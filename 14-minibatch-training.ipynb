{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d422d7e",
   "metadata": {},
   "source": [
    "# Minibatch training\n",
    "\n",
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb436386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the MNIST dataset\n",
    "import gzip\n",
    "import pickle\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import tensor\n",
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "MNIST_URL = \"https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/data/mnist.pkl.gz?raw=true\"\n",
    "\n",
    "data_path = Path(\"data/mnist\")\n",
    "data_path.mkdir(exist_ok=True)\n",
    "gz_path = data_path / \"mnist.pkl.gz\"\n",
    "\n",
    "mpl.rcParams[\"image.cmap\"] = \"gray\"\n",
    "\n",
    "if not gz_path.exists():\n",
    "    urlretrieve(MNIST_URL, gz_path)\n",
    "\n",
    "# File contains a tuple of tuples for the x and y, train and validation data\n",
    "# Images are 28x28\n",
    "with gzip.open(gz_path, \"rb\") as file:\n",
    "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(file, encoding=\"latin-1\")\n",
    "\n",
    "# Put into tensors\n",
    "x_train, y_train, x_valid, y_valid = map(tensor, [x_train, y_train, x_valid, y_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2e66f8",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2dff88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784, tensor(10))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets define some constants that describe the data\n",
    "n_examples, n_pixels = x_train.shape\n",
    "possible_values = y_train.max() + 1\n",
    "\n",
    "# How many nodes/activations/line thingys\n",
    "n_hidden = 50\n",
    "\n",
    "n_examples, n_pixels, possible_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81bc7942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, n_hidden, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in, n_hidden), nn.ReLU(), nn.Linear(n_hidden, n_out)]\n",
    "\n",
    "    def __call__(self, inp):\n",
    "        res = inp\n",
    "        for layer in self.layers:\n",
    "            res = layer(res)\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83614b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(n_pixels, n_hidden, 10)\n",
    "pred = model(x_train)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc24e12",
   "metadata": {},
   "source": [
    "## Cross entropy loss\n",
    "\n",
    "We need to improve our loss function as MSE doesn't make sense, the distance between incorrecd predictions doesn't indicate how good/bad the prediction is. For example if the target is 2, then 3 isnt a better guess than 9.\n",
    "\n",
    "We are outputting a pred for each possible number. As only one is possible at a time our targets are a one hot encoded matrix. If our targets are going to sum to 1, then it makes sense that our preds do too. We can calculate the softmax for each pred. Then for our loss func we compare the softmaxes to the 1 hot encoded targets. As we are 1 hot encoded we can ignore the other targets and just take the log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc60b9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3682, -2.2036, -2.3934,  ..., -2.3103, -2.3528, -2.3528],\n",
       "        [-2.3118, -2.2293, -2.3477,  ..., -2.4072, -2.3332, -2.4887],\n",
       "        [-2.3107, -2.3083, -2.2292,  ..., -2.2186, -2.3733, -2.2416],\n",
       "        ...,\n",
       "        [-2.3486, -2.1997, -2.2944,  ..., -2.2555, -2.3861, -2.3415],\n",
       "        [-2.3534, -2.1716, -2.3589,  ..., -2.3260, -2.3768, -2.3212],\n",
       "        [-2.3240, -2.2793, -2.3415,  ..., -2.3025, -2.4082, -2.3045]],\n",
       "       grad_fn=<LogBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def log_softmax(x):\n",
    "    return (x.exp() / (x.exp().sum(-1, keepdim=True))).log()\n",
    "\n",
    "\n",
    "log_softmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eef8530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3682, -2.2036, -2.3934,  ..., -2.3103, -2.3528, -2.3528],\n",
       "        [-2.3118, -2.2293, -2.3477,  ..., -2.4072, -2.3332, -2.4887],\n",
       "        [-2.3107, -2.3083, -2.2292,  ..., -2.2186, -2.3733, -2.2416],\n",
       "        ...,\n",
       "        [-2.3486, -2.1997, -2.2944,  ..., -2.2555, -2.3861, -2.3415],\n",
       "        [-2.3534, -2.1716, -2.3589,  ..., -2.3260, -2.3768, -2.3212],\n",
       "        [-2.3240, -2.2793, -2.3415,  ..., -2.3025, -2.4082, -2.3045]],\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As log(a/b) = log(a) - log(b), we can simplify things to:\n",
    "\n",
    "\n",
    "def log_softmax(x):\n",
    "    return x - x.exp().sum(-1, keepdim=True).log()\n",
    "\n",
    "\n",
    "log_softmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17fc07c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0130,  0.1516, -0.0382,  ...,  0.0449,  0.0023,  0.0023],\n",
       "        [ 0.0831,  0.1656,  0.0471,  ..., -0.0124,  0.0617, -0.0939],\n",
       "        [ 0.0607,  0.0631,  0.1422,  ...,  0.1528, -0.0019,  0.1298],\n",
       "        ...,\n",
       "        [-0.0156,  0.1332,  0.0385,  ...,  0.0775, -0.0532, -0.0085],\n",
       "        [-0.0248,  0.1570, -0.0303,  ...,  0.0026, -0.0482,  0.0074],\n",
       "        [-0.0280,  0.0167, -0.0455,  ..., -0.0066, -0.1123, -0.0085]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Its possible for the sum of the exponentials of big activations to overflow\n",
    "# pytorch uses some tricks to solve this for use in one function\n",
    "def log_softmax(x):\n",
    "    return x - x.logsumexp(-1, keepdim=True)\n",
    "\n",
    "\n",
    "sm_pred = log_softmax(pred)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc37ef1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4, 1, 9])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How do we index into the preds we want\n",
    "# The y values tell us targets, which are also the index\n",
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfa54dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.3057, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So for each i we want row i and col y_train[i]. eg for pred at row 0\n",
    "sm_pred[0, y_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "482a8b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.3057, -2.3118, -2.4710,  ..., -2.3861, -2.3694, -2.4082],\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can do this for all of them like this\n",
    "sm_pred[range(y_train.shape[0]), y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a20bd29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2933, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So our cross entropy loss function looks like this\n",
    "def nll(inp, target):\n",
    "    return -inp[range(target.shape[0]), target].mean()\n",
    "\n",
    "\n",
    "loss = nll(sm_pred, y_train)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92f174f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2933, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pytorch gives us both of these functions, NLL = negative log likelihood\n",
    "F.nll_loss(F.log_softmax(pred, -1), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79bde23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2933, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And a cross entropy function to do it all in one\n",
    "F.cross_entropy(pred, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a403ade7",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59b42ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.0130,  0.1516, -0.0382,  0.2053, -0.0021,  0.0495,  0.0950,  0.0449,\n",
       "          0.0023,  0.0023], grad_fn=<SelectBackward0>),\n",
       " torch.Size([64, 10]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func = F.cross_entropy\n",
    "batch_size = 64\n",
    "\n",
    "# First we would run a minibatch\n",
    "mini_batch = x_train[0:batch_size]\n",
    "mini_batch_y = y_train[0:batch_size]\n",
    "\n",
    "preds = model(mini_batch)\n",
    "preds[0], preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fba0be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2939, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then we would calculate the loss\n",
    "loss_func(preds, mini_batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98354661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 3, 3, 1, 1, 6, 6, 3, 3, 6, 1, 6, 1, 3, 6, 6, 3, 5, 3, 1, 3, 3, 6, 1,\n",
       "        3, 3, 1, 1, 1, 1, 3, 1, 3, 5, 5, 6, 3, 3, 1, 6, 1, 3, 1, 6, 3, 6, 3, 1,\n",
       "        6, 3, 3, 6, 1, 6, 6, 6, 5, 6, 6, 1, 7, 3, 3, 5])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each of our predictions what did we predict, we need the highest number from each set of preds and get its index\n",
    "preds.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f026fedd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  True, False, False, False,  True, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False,  True, False, False, False, False, False, False,\n",
       "         True, False, False, False, False, False, False, False, False,  True,\n",
       "         True, False, False, False,  True, False, False, False, False,  True,\n",
       "         True, False, False, False, False, False, False, False, False,  True,\n",
       "        False, False, False, False])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see which we got correct\n",
    "preds.argmax(dim=1) == mini_batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4e164b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1562)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use it to calculate accuracy, this isnt needed for the NN but helps us understand whats going on\n",
    "def accuracy(out, targets):\n",
    "    return (out.argmax(dim=1) == targets).float().mean()\n",
    "\n",
    "\n",
    "accuracy(preds, mini_batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0c775ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.2939493656158447 acc:  0.15625\n",
      "loss: 0.18433193862438202 acc:  0.9375\n",
      "loss: 0.17788918316364288 acc:  0.953125\n",
      "loss: 0.13251781463623047 acc:  0.953125\n",
      "loss: 0.0965082049369812 acc:  0.96875\n"
     ]
    }
   ],
   "source": [
    "# Now we want to do all of the batches for a bunch of epochs, updating the weights each time\n",
    "import torch\n",
    "\n",
    "lr = 0.5\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch_start in range(0, n_examples, batch_size):\n",
    "        # Get the slice\n",
    "        sl = slice(batch_start, min(n_examples, batch_start + batch_size))\n",
    "\n",
    "        batch_inp = x_train[sl]\n",
    "        batch_targets = y_train[sl]\n",
    "\n",
    "        # Run the model\n",
    "        preds = model(batch_inp)\n",
    "        loss = loss_func(preds, batch_targets)\n",
    "\n",
    "        if batch_start == 0:\n",
    "            print(\"loss:\", loss.item(), \"acc: \", accuracy(preds, batch_targets).item())\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        with torch.no_grad():\n",
    "            for layer in model.layers:\n",
    "                if hasattr(layer, \"weight\"):\n",
    "                    layer.weight -= layer.weight.grad * lr\n",
    "                    layer.bias -= layer.bias.grad * lr\n",
    "                    layer.weight.grad.zero_()\n",
    "                    layer.bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65abe150",
   "metadata": {},
   "source": [
    "## Parameters and optim\n",
    "\n",
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b4c0c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Module(\n",
       "   (foo): Linear(in_features=3, out_features=4, bias=True)\n",
       " ),\n",
       " [('foo', Linear(in_features=3, out_features=4, bias=True))],\n",
       " [Parameter containing:\n",
       "  tensor([[ 0.3047,  0.2764,  0.5723],\n",
       "          [ 0.4992,  0.0261,  0.5466],\n",
       "          [-0.0185, -0.4649,  0.3647],\n",
       "          [ 0.3825,  0.0715, -0.5044]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.3105, -0.2362, -0.4593,  0.1845], requires_grad=True)])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = nn.Module()\n",
    "m1.foo = nn.Linear(3, 4)\n",
    "\n",
    "# Notice that the Module can automatically track all of the parameters in the\n",
    "# layer that is assigned to it, how does that work?\n",
    "m1, list(m1.named_children()), list(m1.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b41f68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(MLP(\n",
       "   (l1): Linear(in_features=784, out_features=50, bias=True)\n",
       "   (l2): Linear(in_features=50, out_features=10, bias=True)\n",
       "   (relu): ReLU()\n",
       " ),\n",
       " Linear(in_features=784, out_features=50, bias=True),\n",
       " [('l1', Linear(in_features=784, out_features=50, bias=True)),\n",
       "  ('l2', Linear(in_features=50, out_features=10, bias=True)),\n",
       "  ('relu', ReLU())],\n",
       " [torch.Size([50, 784]),\n",
       "  torch.Size([50]),\n",
       "  torch.Size([10, 50]),\n",
       "  torch.Size([10])])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_in, n_hidden, n_out):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_in, n_hidden)\n",
    "        self.l2 = nn.Linear(n_hidden, n_out)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.l2(self.relu(self.l1(x)))\n",
    "\n",
    "\n",
    "# We normally use Module by inheriting from it and assigning it a bynch of layers\n",
    "\n",
    "model = MLP(n_pixels, n_hidden, 10)\n",
    "model, model.l1, list(model.named_children()), list(map(lambda x: x.shape, model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2781a66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.295954704284668 acc:  0.109375\n",
      "loss: 0.10442031174898148 acc:  0.953125\n",
      "loss: 0.11948614567518234 acc:  0.96875\n",
      "loss: 0.10430541634559631 acc:  0.96875\n",
      "loss: 0.10337503999471664 acc:  0.953125\n"
     ]
    }
   ],
   "source": [
    "# So already we can rewrite our loop knowing we can just get all of the params from the model\n",
    "\n",
    "\n",
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for batch_start in range(0, n_examples, batch_size):\n",
    "            # Get the slice\n",
    "            sl = slice(batch_start, min(n_examples, batch_start + batch_size))\n",
    "\n",
    "            batch_inp = x_train[sl]\n",
    "            batch_targets = y_train[sl]\n",
    "\n",
    "            # Run the model\n",
    "            preds = model(batch_inp)\n",
    "            loss = loss_func(preds, batch_targets)\n",
    "\n",
    "            if batch_start == 0:\n",
    "                print(\"loss:\", loss.item(), \"acc: \", accuracy(preds, batch_targets).item())\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the weights\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p -= p.grad * lr\n",
    "                model.zero_grad()\n",
    "\n",
    "\n",
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2141e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': Linear(in_features=784, out_features=50, bias=True), 'l2': Linear(in_features=50, out_features=10, bias=True)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's how we would implement this if nn.Module didn't exist\n",
    "class MyModule:\n",
    "    def __init__(self, n_in, n_hidden, n_out):\n",
    "        self._modules = {}\n",
    "        self.l1 = nn.Linear(n_in, n_hidden)\n",
    "        self.l2 = nn.Linear(n_hidden, n_out)\n",
    "\n",
    "    # We hook into setattr and update _modules when some sets something new\n",
    "    def __setattr__(self, key, value):\n",
    "        if not key.startswith(\"_\"):\n",
    "            self._modules[key] = value\n",
    "        super().__setattr__(key, value)\n",
    "\n",
    "    # Print modules\n",
    "    def __repr__(self):\n",
    "        return f\"{self._modules}\"\n",
    "\n",
    "    # Generate the parameters of every module\n",
    "    def parameters(self):\n",
    "        for mod in self.modules.values():\n",
    "            for p in mod.parameters():\n",
    "                yield p\n",
    "\n",
    "\n",
    "myM = MyModule(n_pixels, n_hidden, 10)\n",
    "myM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8222f74d",
   "metadata": {},
   "source": [
    "### Registering modules\n",
    "\n",
    "We previously stored all our layers in a .layers member. How would we do that with nn.module. You can manually add layers using `add_module`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8f73943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (layer_0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (layer_1): ReLU()\n",
       "  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "\n",
    "        for idx, layer in enumerate(self.layers):\n",
    "            self.add_module(f\"layer_{idx}\", layer)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return reduce(lambda val, layer: layer(val), self.layers, x)\n",
    "\n",
    "\n",
    "layers = [nn.Linear(n_pixels, n_hidden), nn.ReLU(), nn.Linear(n_hidden, 10)]\n",
    "model = Model(layers)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0696d463",
   "metadata": {},
   "source": [
    "#### nn.ModuleList\n",
    "\n",
    "`nn.ModuleList` does this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0cf60495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialModel(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SequentialModel(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = SequentialModel(layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fde8205b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.316998243331909 acc:  0.125\n",
      "loss: 0.17858779430389404 acc:  0.9375\n",
      "loss: 0.15072037279605865 acc:  0.953125\n",
      "loss: 0.17366889119148254 acc:  0.96875\n",
      "loss: 0.1267264485359192 acc:  0.96875\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25312b9b",
   "metadata": {},
   "source": [
    "#### nn.Sequential\n",
    "\n",
    "`nn.Sequential` already exists and does the lot for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47539531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = [nn.Linear(n_pixels, n_hidden), nn.ReLU(), nn.Linear(n_hidden, 10)]\n",
    "model = nn.Sequential(*layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b34e62d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.315805196762085 acc:  0.0625\n",
      "loss: 0.1865747720003128 acc:  0.9375\n",
      "loss: 0.08276090770959854 acc:  0.96875\n",
      "loss: 0.08583660423755646 acc:  0.96875\n",
      "loss: 0.03434313088655472 acc:  1.0\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa0a54c",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27ea808b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could put our optimisation steps into a class\n",
    "\n",
    "\n",
    "class Optimizer:\n",
    "    def __init__(self, params, lr=0.5):\n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "\n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params:\n",
    "                p -= p.grad * self.lr\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.params:\n",
    "            p.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d58616fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.297377109527588 acc:  0.0625\n",
      "loss: 0.18612894415855408 acc:  0.9375\n",
      "loss: 0.15381328761577606 acc:  0.9375\n",
      "loss: 0.13656480610370636 acc:  0.9375\n",
      "loss: 0.09828701615333557 acc:  0.96875\n"
     ]
    }
   ],
   "source": [
    "layers = [nn.Linear(n_pixels, n_hidden), nn.ReLU(), nn.Linear(n_hidden, 10)]\n",
    "model = nn.Sequential(*layers)\n",
    "opt = Optimizer(model.parameters())\n",
    "\n",
    "\n",
    "# And now our training loop will look like this\n",
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for batch_start in range(0, n_examples, batch_size):\n",
    "            # Get the slice\n",
    "            sl = slice(batch_start, min(n_examples, batch_start + batch_size))\n",
    "\n",
    "            batch_inp = x_train[sl]\n",
    "            batch_targets = y_train[sl]\n",
    "\n",
    "            # Run the model\n",
    "            preds = model(batch_inp)\n",
    "            loss = loss_func(preds, batch_targets)\n",
    "\n",
    "            if batch_start == 0:\n",
    "                print(\"loss:\", loss.item(), \"acc: \", accuracy(preds, batch_targets).item())\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the weights\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "\n",
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0eddcbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.31352162361145 acc:  0.109375\n",
      "loss: 0.14608719944953918 acc:  0.953125\n",
      "loss: 0.0877109169960022 acc:  0.96875\n",
      "loss: 0.05135871097445488 acc:  0.96875\n",
      "loss: 0.0472152940928936 acc:  0.96875\n"
     ]
    }
   ],
   "source": [
    "# pytorch gives use this as well\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    layers = [nn.Linear(n_pixels, n_hidden), nn.ReLU(), nn.Linear(n_hidden, 10)]\n",
    "    model = nn.Sequential(*layers)\n",
    "    opt = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    return model, opt\n",
    "\n",
    "\n",
    "model, opt = get_model()\n",
    "\n",
    "\n",
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for batch_start in range(0, n_examples, batch_size):\n",
    "            # Get the slice\n",
    "            sl = slice(batch_start, min(n_examples, batch_start + batch_size))\n",
    "\n",
    "            batch_inp = x_train[sl]\n",
    "            batch_targets = y_train[sl]\n",
    "\n",
    "            # Run the model\n",
    "            preds = model(batch_inp)\n",
    "            loss = loss_func(preds, batch_targets)\n",
    "\n",
    "            if batch_start == 0:\n",
    "                print(\"loss:\", loss.item(), \"acc: \", accuracy(preds, batch_targets).item())\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the weights\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "\n",
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332003b4",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader\n",
    "\n",
    "What if we want to more easily iterate through minimatches and x/y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "944963fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10000)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.x[i], self.y[i]\n",
    "\n",
    "\n",
    "train_ds = Dataset(x_train, y_train)\n",
    "valid_ds = Dataset(x_valid, y_valid)\n",
    "\n",
    "len(train_ds), len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f6258cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       "  tensor([5, 0, 4, 1, 9])),\n",
       " torch.Size([5, 784]),\n",
       " torch.Size([5]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# __getitem__ works with tensors\n",
    "train_ds[0:5], train_ds[0:5][0].shape, train_ds[0:5][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f98d9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.3270351886749268 acc:  0.078125\n",
      "loss: 0.15340012311935425 acc:  0.9375\n",
      "loss: 0.15084929764270782 acc:  0.921875\n",
      "loss: 0.1238880455493927 acc:  0.9375\n",
      "loss: 0.08751741796731949 acc:  0.953125\n"
     ]
    }
   ],
   "source": [
    "# We can now simplify the slicing\n",
    "\n",
    "\n",
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for batch_start in range(0, n_examples, batch_size):\n",
    "            # Get the slice\n",
    "            sl = slice(batch_start, min(n_examples, batch_start + batch_size))\n",
    "\n",
    "            batch_inp, batch_targets = train_ds[batch_start : min(n_examples, batch_start + batch_size)]\n",
    "\n",
    "            # Run the model\n",
    "            preds = model(batch_inp)\n",
    "            loss = loss_func(preds, batch_targets)\n",
    "\n",
    "            if batch_start == 0:\n",
    "                print(\"loss:\", loss.item(), \"acc: \", accuracy(preds, batch_targets).item())\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the weights\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "\n",
    "model, opt = get_model()\n",
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d5918a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A DataLoader is an iterator that will help us with looping over the minibatches\n",
    "\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, dataset, batch_size):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch_start in range(0, len(self.dataset), batch_size):\n",
    "            yield self.dataset[batch_start : batch_start + self.batch_size]\n",
    "\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size)\n",
    "valid_dl = DataLoader(valid_ds, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "26423d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5205250382423401 acc:  0.875\n",
      "loss: 0.26634106040000916 acc:  0.875\n",
      "loss: 0.08028078824281693 acc:  1.0\n",
      "loss: 0.02806195430457592 acc:  1.0\n",
      "loss: 0.036086585372686386 acc:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Now we can remove the slicing form our loop\n",
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for batch_inp, batch_targets in train_dl:\n",
    "            # Run the model\n",
    "            preds = model(batch_inp)\n",
    "            loss = loss_func(preds, batch_targets)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the weights\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        print(\"loss:\", loss.item(), \"acc: \", accuracy(preds, batch_targets).item())\n",
    "\n",
    "\n",
    "model, opt = get_model()\n",
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f522dc44",
   "metadata": {},
   "source": [
    "## Random sampling\n",
    "\n",
    "What if we want our training set to be in a random order that differs every iteration (but keep the validations set the ssame)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f40cb11a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4], [8989, 15354, 49658, 32012, 39419])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "# Iterates over indices that  may or may not be shuffled\n",
    "class Sampler:\n",
    "    def __init__(self, dataset, shuffle=False):\n",
    "        self.N = len(dataset)\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        # List indices for the dataset\n",
    "        indices = list(range(self.N))\n",
    "\n",
    "        if self.shuffle:\n",
    "            random.shuffle(indices)\n",
    "\n",
    "        return iter(indices)\n",
    "\n",
    "\n",
    "list(Sampler(train_ds))[:5], list(Sampler(train_ds, True))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b46b1a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[20896, 14995], [3185, 3092], [33569, 38996], [19244, 35012], [25790, 27146]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastcore.all as fc\n",
    "\n",
    "\n",
    "# Gets batches of the indices given by a sampler\n",
    "class BatchSampler:\n",
    "    def __init__(self, sampler, batch_size, drop_last=False):\n",
    "        fc.store_attr()  # Stores all inputs as members with same name\n",
    "\n",
    "    def __iter__(self):\n",
    "        for chunk in fc.chunked(iter(self.sampler), self.batch_size, drop_last=self.drop_last):\n",
    "            yield chunk\n",
    "\n",
    "\n",
    "# Batches of 2, randomised\n",
    "list(BatchSampler(Sampler(train_ds, True), 2))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "195f357e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       "  tensor([1, 0, 3, 7, 8, 1, 9, 6, 5, 8, 4, 2, 3, 2, 2, 1, 3, 7, 5, 2, 8, 7, 6, 4,\n",
       "          4, 1, 8, 6, 1, 9, 2, 1, 2, 0, 2, 8, 4, 3, 3, 6, 2, 5, 8, 4, 6, 3, 4, 7,\n",
       "          5, 7, 5, 7, 4, 1, 2, 3, 5, 2, 1, 6, 9, 6, 2, 2])),\n",
       " torch.Size([64, 784]),\n",
       " torch.Size([64]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can update the DataLoader to use a BatchSampler rather than being told a batch size\n",
    "\n",
    "\n",
    "# We need a collation function to stack all of the Xs and all of the Ys together into tensors\n",
    "def collate(data):\n",
    "    data_x, data_y = zip(*data)\n",
    "    return torch.stack(data_x), torch.stack(data_y)\n",
    "\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, dataset, batch_sampler, collate_fn=collate):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __iter__(self):\n",
    "        yield from (self.collate_fn(self.dataset[i] for i in b) for b in self.batch_sampler)\n",
    "\n",
    "\n",
    "train_samp = BatchSampler(Sampler(train_ds, shuffle=True), batch_size)\n",
    "valid_samp = BatchSampler(Sampler(valid_ds, shuffle=False), batch_size)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_sampler=train_samp)\n",
    "valid_dl = DataLoader(valid_ds, batch_sampler=valid_samp)\n",
    "\n",
    "batch = next(iter(train_dl))\n",
    "batch, batch[0].shape, batch[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e8bd5df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.05326978117227554 acc:  1.0\n",
      "loss: 0.12145218253135681 acc:  0.9375\n",
      "loss: 0.11459718644618988 acc:  0.9375\n",
      "loss: 0.15202879905700684 acc:  0.9375\n",
      "loss: 0.01949377916753292 acc:  1.0\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756c19c8",
   "metadata": {},
   "source": [
    "### Multiprocessing DataLoader\n",
    "\n",
    "What if we want to run this in parallel to speed things up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1af7fb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([1, 1]))\n",
      "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([1, 0]))\n"
     ]
    }
   ],
   "source": [
    "# We want to be able to process something a bit like this but in parallel\n",
    "for o in map(train_ds.__getitem__, ([3, 6], [8, 1])):\n",
    "    print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a091ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.1121179386973381 acc:  0.875\n",
      "loss: 0.21432000398635864 acc:  0.9375\n",
      "loss: 0.019699424505233765 acc:  1.0\n",
      "loss: 0.19220580160617828 acc:  0.875\n",
      "loss: 0.28950852155685425 acc:  0.875\n"
     ]
    }
   ],
   "source": [
    "# Pytorch gives us all of these and supports multiprocessing\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler, BatchSampler\n",
    "\n",
    "train_samp = BatchSampler(RandomSampler(train_ds), batch_size, drop_last=False)\n",
    "valid_samp = BatchSampler(SequentialSampler(valid_ds), batch_size, drop_last=False)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_sampler=train_samp, collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, batch_sampler=valid_samp, collate_fn=collate)\n",
    "\n",
    "model, opt = get_model()\n",
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12af9fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.525796413421631 acc:  0.0\n",
      "loss: 3.250904083251953 acc:  0.0\n",
      "loss: 2.5235815048217773 acc:  0.0\n",
      "loss: 2.464507579803467 acc:  0.0\n",
      "loss: 2.1057496070861816 acc:  0.0\n"
     ]
    }
   ],
   "source": [
    "# We can also pass a batch sampler as a sampler as we are able to index multiple things at once with no collate\n",
    "# pytorch kust autogens a BatchSampler for us\n",
    "train_dl = DataLoader(train_ds, sampler=train_samp)\n",
    "valid_dl = DataLoader(valid_ds, sampler=valid_samp)\n",
    "\n",
    "# As random sampling is so common, we can also just pass shuffle flags, and that dataset\n",
    "train_dl = DataLoader(train_ds, shuffle=True, drop_last=True)\n",
    "valid_dl = DataLoader(valid_ds, shuffle=False)\n",
    "\n",
    "model, opt = get_model()\n",
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aec3904",
   "metadata": {},
   "source": [
    "## Validation\n",
    "\n",
    "We've not done anything with the validation set yet. Lets update fit to take in a validation set. We'll print the validation loss for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3c3eec58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.16989297520160676, acc: 0.94822\n",
      "epoch: 1, loss: 0.21148953001499177, acc: 0.93568\n",
      "epoch: 2, loss: 0.09376879837676882, acc: 0.9701\n",
      "epoch: 3, loss: 0.07792397175550461, acc: 0.97562\n",
      "epoch: 4, loss: 0.05999621275998652, acc: 0.98044\n"
     ]
    }
   ],
   "source": [
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        # Some layers behave differently during training and validation so we have to tell them\n",
    "        model.train()\n",
    "        for batch_inp, batch_targets in train_dl:\n",
    "            # Run the model\n",
    "            preds = model(batch_inp)\n",
    "            loss = loss_func(preds, batch_targets)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the weights\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "        # Now run the validation set\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            total_loss = 0.0\n",
    "            total_acc = 0.0\n",
    "            count = 0\n",
    "\n",
    "            for batch_inp, batch_targets in train_dl:\n",
    "                preds = model(batch_inp)\n",
    "\n",
    "                count += len(batch_inp)\n",
    "                total_loss += loss_func(preds, batch_targets).item() * len(batch_inp)\n",
    "                total_acc += accuracy(preds, batch_targets).item() * len(batch_inp)\n",
    "\n",
    "        total_loss /= count\n",
    "        total_acc /= count\n",
    "        print(f\"epoch: {epoch}, loss: {total_loss}, acc: {total_acc}\")\n",
    "\n",
    "    return total_loss, total_acc\n",
    "\n",
    "\n",
    "def get_dls(train_ds, valid_ds, batch_size, **kwargs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=batch_size, shuffle=True, **kwargs),\n",
    "        DataLoader(valid_ds, batch_size=batch_size * 2, **kwargs),\n",
    "    )\n",
    "\n",
    "\n",
    "train_dl, valid_dl = get_dls(train_ds, valid_ds, 64)\n",
    "model, opt = get_model()\n",
    "loss, acc = fit(5, model, F.cross_entropy, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e67310",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
