{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acd6955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf3c0308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f022b06",
   "metadata": {},
   "source": [
    "# Minibatch training\n",
    "\n",
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8149409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the MNIST dataset\n",
    "import gzip\n",
    "import pickle\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import tensor\n",
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "MNIST_URL = \"https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/data/mnist.pkl.gz?raw=true\"\n",
    "\n",
    "data_path = Path(\"data/mnist\")\n",
    "data_path.mkdir(exist_ok=True)\n",
    "gz_path = data_path / \"mnist.pkl.gz\"\n",
    "\n",
    "mpl.rcParams[\"image.cmap\"] = \"gray\"\n",
    "\n",
    "if not gz_path.exists():\n",
    "    urlretrieve(MNIST_URL, gz_path)\n",
    "\n",
    "# File contains a tuple of tuples for the x and y, train and validation data\n",
    "# Images are 28x28\n",
    "with gzip.open(gz_path, \"rb\") as file:\n",
    "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(file, encoding=\"latin-1\")\n",
    "\n",
    "# Put into tensors\n",
    "x_train, y_train, x_valid, y_valid = map(tensor, [x_train, y_train, x_valid, y_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d031e7d0",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a43fee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784, tensor(10))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets define some constants that describe the data\n",
    "n_examples, n_pixels = x_train.shape\n",
    "possible_values = y_train.max() + 1\n",
    "\n",
    "# How many nodes/activations/line thingys\n",
    "n_hidden = 50\n",
    "\n",
    "n_examples, n_pixels, possible_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10270c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, n_hidden, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in, n_hidden), nn.ReLU(), nn.Linear(n_hidden, n_out)]\n",
    "\n",
    "    def __call__(self, inp):\n",
    "        res = inp\n",
    "        for layer in self.layers:\n",
    "            res = layer(res)\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55fb337f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 10])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(n_pixels, n_hidden, 10)\n",
    "pred = model(x_train)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e13b95",
   "metadata": {},
   "source": [
    "## Cross entropy loss\n",
    "\n",
    "We need to improve our loss function as MSE doesn't make sense, the distance between incorrecd predictions doesn't indicate how good/bad the prediction is. For example if the target is 2, then 3 isnt a better guess than 9.\n",
    "\n",
    "We are outputting a pred for each possible number. As only one is possible at a time our targets are a one hot encoded matrix. If our targets are going to sum to 1, then it makes sense that our preds do too. We can calculate the softmax for each pred. Then for our loss func we compare the softmaxes to the 1 hot encoded targets. As we are 1 hot encoded we can ignore the other targets and just take the log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39e4127a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.2133, -2.4044, -2.4511,  ..., -2.2895, -2.1803, -2.3687],\n",
       "        [-2.2759, -2.4379, -2.4651,  ..., -2.2692, -2.2075, -2.3586],\n",
       "        [-2.3169, -2.4823, -2.4626,  ..., -2.1798, -2.1605, -2.2436],\n",
       "        ...,\n",
       "        [-2.2795, -2.4837, -2.4338,  ..., -2.2089, -2.1821, -2.2838],\n",
       "        [-2.2791, -2.4615, -2.4212,  ..., -2.1493, -2.1313, -2.3059],\n",
       "        [-2.4028, -2.4987, -2.5289,  ..., -2.1593, -2.0554, -2.2555]],\n",
       "       grad_fn=<LogBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def log_softmax(x):\n",
    "    return (x.exp() / (x.exp().sum(-1, keepdim=True))).log()\n",
    "\n",
    "\n",
    "log_softmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2d3867e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.2133, -2.4044, -2.4511,  ..., -2.2895, -2.1803, -2.3687],\n",
       "        [-2.2759, -2.4379, -2.4651,  ..., -2.2692, -2.2075, -2.3586],\n",
       "        [-2.3169, -2.4823, -2.4626,  ..., -2.1798, -2.1605, -2.2436],\n",
       "        ...,\n",
       "        [-2.2795, -2.4837, -2.4338,  ..., -2.2089, -2.1821, -2.2838],\n",
       "        [-2.2791, -2.4615, -2.4212,  ..., -2.1493, -2.1313, -2.3059],\n",
       "        [-2.4028, -2.4987, -2.5289,  ..., -2.1593, -2.0554, -2.2555]],\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As log(a/b) = log(a) - log(b), we can simplify things to:\n",
    "\n",
    "\n",
    "def log_softmax(x):\n",
    "    return x - x.exp().sum(-1, keepdim=True).log()\n",
    "\n",
    "\n",
    "log_softmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dce7ed70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1150, -0.0761, -0.1229,  ...,  0.0388,  0.1480, -0.0405],\n",
       "        [ 0.0448, -0.1172, -0.1444,  ...,  0.0515,  0.1132, -0.0379],\n",
       "        [-0.0048, -0.1703, -0.1506,  ...,  0.1323,  0.1515,  0.0684],\n",
       "        ...,\n",
       "        [ 0.0600, -0.1443, -0.0943,  ...,  0.1306,  0.1574,  0.0557],\n",
       "        [ 0.0350, -0.1474, -0.1071,  ...,  0.1648,  0.1828,  0.0082],\n",
       "        [-0.0907, -0.1867, -0.2168,  ...,  0.1528,  0.2567,  0.0566]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Its possible for the sum of the exponentials of big activations to overflow\n",
    "# pytorch uses some tricks to solve this for use in one function\n",
    "def log_softmax(x):\n",
    "    return x - x.logsumexp(-1, keepdim=True)\n",
    "\n",
    "\n",
    "sm_pred = log_softmax(pred)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f081b9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4, 1, 9])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How do we index into the preds we want\n",
    "# The y values tell us targets, which are also the index\n",
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8c24d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.1109, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So for each i we want row i and col y_train[i]. eg for pred at row 0\n",
    "sm_pred[0, y_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f736a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.1109, -2.2759, -2.2591,  ..., -2.1821, -2.2817, -2.0554],\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can do this for all of them like this\n",
    "sm_pred[range(y_train.shape[0]), y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbf1024c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3124, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So our cross entropy loss function looks like this\n",
    "def nll(inp, target):\n",
    "    return -inp[range(target.shape[0]), target].mean()\n",
    "\n",
    "\n",
    "loss = nll(sm_pred, y_train)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24e1b430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3124, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pytorch gives us both of these functions, NLL = negative log likelihood\n",
    "F.nll_loss(F.log_softmax(pred, -1), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "206b797f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3124, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And a cross entropy function to do it all in one\n",
    "F.cross_entropy(pred, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419e6cb8",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94ed32f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.1150, -0.0761, -0.1229, -0.2367,  0.1981,  0.2174, -0.0872,  0.0388,\n",
       "          0.1480, -0.0405], grad_fn=<SelectBackward0>),\n",
       " torch.Size([64, 10]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func = F.cross_entropy\n",
    "batch_size = 64\n",
    "\n",
    "# First we would run a minibatch\n",
    "mini_batch = x_train[0:batch_size]\n",
    "mini_batch_y = y_train[0:batch_size]\n",
    "\n",
    "preds = model(mini_batch)\n",
    "preds[0], preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cad3eaa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3258, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then we would calculate the loss\n",
    "loss_func(preds, mini_batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20cfa18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 5, 5, 5, 8, 8, 8, 8, 4, 5, 8, 5, 8, 5, 5, 8, 5, 5, 5, 5, 7, 5, 5, 5,\n",
       "        5, 8, 5, 8, 8, 7, 8, 5, 5, 5, 5, 5, 8, 5, 5, 8, 4, 5, 7, 8, 8, 4, 8, 5,\n",
       "        5, 5, 5, 8, 8, 5, 5, 5, 8, 4, 8, 5, 5, 5, 5, 8])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each of our predictions what did we predict, we need the highest number from each set of preds and get its index\n",
    "preds.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30f56b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True, False, False, False, False, False, False, False, False, False,\n",
       "        False,  True, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,  True,\n",
       "        False, False, False, False, False,  True, False, False, False, False,\n",
       "        False, False,  True, False, False, False,  True,  True, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see which we got correct\n",
    "preds.argmax(dim=1) == mini_batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "822e4f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "\n",
    "# We can use it to calculate accuracy, this isnt needed for the NN but helps us understand whats going on\n",
    "def accuracy(out, targets):\n",
    "    return (out.argmax(dim=1) == targets).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff79d905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1094)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(preds, mini_batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb07e668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.3258378505706787 acc:  0.109375\n",
      "loss: 0.1734699010848999 acc:  0.9375\n",
      "loss: 0.1648125946521759 acc:  0.953125\n",
      "loss: 0.1431054323911667 acc:  0.953125\n",
      "loss: 0.159428671002388 acc:  0.953125\n"
     ]
    }
   ],
   "source": [
    "# Now we want to do all of the batches for a bunch of epochs, updating the weights each time\n",
    "import torch\n",
    "\n",
    "lr = 0.5\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch_start in range(0, n_examples, batch_size):\n",
    "        # Get the slice\n",
    "        sl = slice(batch_start, min(n_examples, batch_start + batch_size))\n",
    "\n",
    "        batch_inp = x_train[sl]\n",
    "        batch_targets = y_train[sl]\n",
    "\n",
    "        # Run the model\n",
    "        preds = model(batch_inp)\n",
    "        loss = loss_func(preds, batch_targets)\n",
    "\n",
    "        if batch_start == 0:\n",
    "            print(\"loss:\", loss.item(), \"acc: \", accuracy(preds, batch_targets).item())\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        with torch.no_grad():\n",
    "            for layer in model.layers:\n",
    "                if hasattr(layer, \"weight\"):\n",
    "                    layer.weight -= layer.weight.grad * lr\n",
    "                    layer.bias -= layer.bias.grad * lr\n",
    "                    layer.weight.grad.zero_()\n",
    "                    layer.bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7771ffcb",
   "metadata": {},
   "source": [
    "## Parameters and optim\n",
    "\n",
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89b511fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Module(\n",
       "   (foo): Linear(in_features=3, out_features=4, bias=True)\n",
       " ),\n",
       " [('foo', Linear(in_features=3, out_features=4, bias=True))],\n",
       " [Parameter containing:\n",
       "  tensor([[-0.0402,  0.2272, -0.5387],\n",
       "          [ 0.0365,  0.4104,  0.3436],\n",
       "          [ 0.4707,  0.5491, -0.3349],\n",
       "          [-0.5585, -0.5419,  0.1093]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.1976,  0.5090,  0.3565,  0.4564], requires_grad=True)])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = nn.Module()\n",
    "m1.foo = nn.Linear(3, 4)\n",
    "\n",
    "# Notice that the Module can automatically track all of the parameters in the\n",
    "# layer that is assigned to it, how does that work?\n",
    "m1, list(m1.named_children()), list(m1.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98290238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(MLP(\n",
       "   (l1): Linear(in_features=784, out_features=50, bias=True)\n",
       "   (l2): Linear(in_features=50, out_features=10, bias=True)\n",
       "   (relu): ReLU()\n",
       " ),\n",
       " Linear(in_features=784, out_features=50, bias=True),\n",
       " [('l1', Linear(in_features=784, out_features=50, bias=True)),\n",
       "  ('l2', Linear(in_features=50, out_features=10, bias=True)),\n",
       "  ('relu', ReLU())],\n",
       " [torch.Size([50, 784]),\n",
       "  torch.Size([50]),\n",
       "  torch.Size([10, 50]),\n",
       "  torch.Size([10])])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_in, n_hidden, n_out):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_in, n_hidden)\n",
    "        self.l2 = nn.Linear(n_hidden, n_out)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.l2(self.relu(self.l1(x)))\n",
    "\n",
    "\n",
    "# We normally use Module by inheriting from it and assigning it a bynch of layers\n",
    "\n",
    "model = MLP(n_pixels, n_hidden, 10)\n",
    "model, model.l1, list(model.named_children()), list(map(lambda x: x.shape, model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b080706a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.299609899520874 acc:  0.09375\n",
      "loss: 0.1553519368171692 acc:  0.953125\n",
      "loss: 0.13272824883460999 acc:  0.953125\n",
      "loss: 0.10512181371450424 acc:  0.96875\n",
      "loss: 0.09392286092042923 acc:  0.96875\n"
     ]
    }
   ],
   "source": [
    "# So already we can rewrite our loop knowing we can just get all of the params from the model\n",
    "\n",
    "\n",
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for batch_start in range(0, n_examples, batch_size):\n",
    "            # Get the slice\n",
    "            sl = slice(batch_start, min(n_examples, batch_start + batch_size))\n",
    "\n",
    "            batch_inp = x_train[sl]\n",
    "            batch_targets = y_train[sl]\n",
    "\n",
    "            # Run the model\n",
    "            preds = model(batch_inp)\n",
    "            loss = loss_func(preds, batch_targets)\n",
    "\n",
    "            if batch_start == 0:\n",
    "                print(\"loss:\", loss.item(), \"acc: \", accuracy(preds, batch_targets).item())\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the weights\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p -= p.grad * lr\n",
    "                model.zero_grad()\n",
    "\n",
    "\n",
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5454f308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': Linear(in_features=784, out_features=50, bias=True), 'l2': Linear(in_features=50, out_features=10, bias=True)}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's how we would implement this if nn.Module didn't exist\n",
    "class MyModule:\n",
    "    def __init__(self, n_in, n_hidden, n_out):\n",
    "        self._modules = {}\n",
    "        self.l1 = nn.Linear(n_in, n_hidden)\n",
    "        self.l2 = nn.Linear(n_hidden, n_out)\n",
    "\n",
    "    # We hook into setattr and update _modules when some sets something new\n",
    "    def __setattr__(self, key, value):\n",
    "        if not key.startswith(\"_\"):\n",
    "            self._modules[key] = value\n",
    "        super().__setattr__(key, value)\n",
    "\n",
    "    # Print modules\n",
    "    def __repr__(self):\n",
    "        return f\"{self._modules}\"\n",
    "\n",
    "    # Generate the parameters of every module\n",
    "    def parameters(self):\n",
    "        for mod in self.modules.values():\n",
    "            for p in mod.parameters():\n",
    "                yield p\n",
    "\n",
    "\n",
    "myM = MyModule(n_pixels, n_hidden, 10)\n",
    "myM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d2b08f",
   "metadata": {},
   "source": [
    "### Registering modules\n",
    "\n",
    "We previously stored all our layers in a .layers member. How would we do that with nn.module. You can manually add layers using `add_module`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9832f8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (layer_0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (layer_1): ReLU()\n",
       "  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "\n",
    "        for idx, layer in enumerate(self.layers):\n",
    "            self.add_module(f\"layer_{idx}\", layer)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return reduce(lambda val, layer: layer(val), self.layers, x)\n",
    "\n",
    "\n",
    "layers = [nn.Linear(n_pixels, n_hidden), nn.ReLU(), nn.Linear(n_hidden, 10)]\n",
    "model = Model(layers)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730c9d2f",
   "metadata": {},
   "source": [
    "#### nn.ModuleList\n",
    "\n",
    "`nn.ModuleList` does this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90715075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialModel(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SequentialModel(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = SequentialModel(layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "927d5fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.341370105743408 acc:  0.015625\n",
      "loss: 0.11918908357620239 acc:  0.96875\n",
      "loss: 0.14029745757579803 acc:  0.96875\n",
      "loss: 0.11141327768564224 acc:  0.953125\n",
      "loss: 0.09101451188325882 acc:  0.953125\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf3078a",
   "metadata": {},
   "source": [
    "#### nn.Sequential\n",
    "\n",
    "`nn.Sequential` already exists and does the lot for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f254a90f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = [nn.Linear(n_pixels, n_hidden), nn.ReLU(), nn.Linear(n_hidden, 10)]\n",
    "model = nn.Sequential(*layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6410aff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.29732346534729 acc:  0.140625\n",
      "loss: 0.1326911747455597 acc:  0.96875\n",
      "loss: 0.12029773741960526 acc:  0.953125\n",
      "loss: 0.11310149729251862 acc:  0.96875\n",
      "loss: 0.1144457533955574 acc:  0.96875\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20422e48",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f30313f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could put our optimisation steps into a class\n",
    "\n",
    "\n",
    "class Optimizer:\n",
    "    def __init__(self, params, lr=0.5):\n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "\n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params:\n",
    "                p -= p.grad * self.lr\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.params:\n",
    "            p.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99bb912e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.326862096786499 acc:  0.140625\n",
      "loss: 0.1396191567182541 acc:  0.953125\n",
      "loss: 0.13144434988498688 acc:  0.953125\n",
      "loss: 0.0914166048169136 acc:  0.984375\n",
      "loss: 0.06785164028406143 acc:  0.984375\n"
     ]
    }
   ],
   "source": [
    "layers = [nn.Linear(n_pixels, n_hidden), nn.ReLU(), nn.Linear(n_hidden, 10)]\n",
    "model = nn.Sequential(*layers)\n",
    "opt = Optimizer(model.parameters())\n",
    "\n",
    "\n",
    "# And now our training loop will look like this\n",
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for batch_start in range(0, n_examples, batch_size):\n",
    "            # Get the slice\n",
    "            sl = slice(batch_start, min(n_examples, batch_start + batch_size))\n",
    "\n",
    "            batch_inp = x_train[sl]\n",
    "            batch_targets = y_train[sl]\n",
    "\n",
    "            # Run the model\n",
    "            preds = model(batch_inp)\n",
    "            loss = loss_func(preds, batch_targets)\n",
    "\n",
    "            if batch_start == 0:\n",
    "                print(\"loss:\", loss.item(), \"acc: \", accuracy(preds, batch_targets).item())\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the weights\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "\n",
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6105680e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.3191866874694824 acc:  0.109375\n",
      "loss: 0.24167746305465698 acc:  0.90625\n",
      "loss: 0.1405819058418274 acc:  0.953125\n",
      "loss: 0.10254921019077301 acc:  0.96875\n",
      "loss: 0.07964211702346802 acc:  0.96875\n"
     ]
    }
   ],
   "source": [
    "# pytorch gives use this as well\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    layers = [nn.Linear(n_pixels, n_hidden), nn.ReLU(), nn.Linear(n_hidden, 10)]\n",
    "    model = nn.Sequential(*layers)\n",
    "    opt = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    return model, opt\n",
    "\n",
    "\n",
    "model, opt = get_model()\n",
    "\n",
    "\n",
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for batch_start in range(0, n_examples, batch_size):\n",
    "            # Get the slice\n",
    "            sl = slice(batch_start, min(n_examples, batch_start + batch_size))\n",
    "\n",
    "            batch_inp = x_train[sl]\n",
    "            batch_targets = y_train[sl]\n",
    "\n",
    "            # Run the model\n",
    "            preds = model(batch_inp)\n",
    "            loss = loss_func(preds, batch_targets)\n",
    "\n",
    "            if batch_start == 0:\n",
    "                print(\"loss:\", loss.item(), \"acc: \", accuracy(preds, batch_targets).item())\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the weights\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "\n",
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b0ab7f",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader\n",
    "\n",
    "What if we want to more easily iterate through minimatches and x/y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e02f515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.x[i], self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3e094c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10000)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = Dataset(x_train, y_train)\n",
    "valid_ds = Dataset(x_valid, y_valid)\n",
    "\n",
    "len(train_ds), len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e5d48144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       "  tensor([5, 0, 4, 1, 9])),\n",
       " torch.Size([5, 784]),\n",
       " torch.Size([5]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# __getitem__ works with tensors\n",
    "train_ds[0:5], train_ds[0:5][0].shape, train_ds[0:5][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2a00533f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.2971205711364746 acc:  0.140625\n",
      "loss: 0.14574120938777924 acc:  0.953125\n",
      "loss: 0.17029577493667603 acc:  0.953125\n",
      "loss: 0.15515412390232086 acc:  0.96875\n",
      "loss: 0.15817898511886597 acc:  0.96875\n"
     ]
    }
   ],
   "source": [
    "# We can now simplify the slicing\n",
    "\n",
    "\n",
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for batch_start in range(0, n_examples, batch_size):\n",
    "            # Get the slice\n",
    "            sl = slice(batch_start, min(n_examples, batch_start + batch_size))\n",
    "\n",
    "            batch_inp, batch_targets = train_ds[batch_start : min(n_examples, batch_start + batch_size)]\n",
    "\n",
    "            # Run the model\n",
    "            preds = model(batch_inp)\n",
    "            loss = loss_func(preds, batch_targets)\n",
    "\n",
    "            if batch_start == 0:\n",
    "                print(\"loss:\", loss.item(), \"acc: \", accuracy(preds, batch_targets).item())\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the weights\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "\n",
    "model, opt = get_model()\n",
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e7b3e33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A DataLoader is an iterator that will help us with looping over the minibatches\n",
    "\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, dataset, batch_size):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch_start in range(0, len(self.dataset), batch_size):\n",
    "            yield self.dataset[batch_start : batch_start + self.batch_size]\n",
    "\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size)\n",
    "valid_dl = DataLoader(valid_ds, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9d3d097e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.13620899617671967 acc:  0.9375\n",
      "loss: 0.11623474955558777 acc:  1.0\n",
      "loss: 0.08376095443964005 acc:  1.0\n",
      "loss: 0.04591038078069687 acc:  1.0\n",
      "loss: 0.018032046034932137 acc:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Now we can remove the slicing form our loop\n",
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for batch_inp, batch_targets in train_dl:\n",
    "            # Run the model\n",
    "            preds = model(batch_inp)\n",
    "            loss = loss_func(preds, batch_targets)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the weights\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        print(\"loss:\", loss.item(), \"acc: \", accuracy(preds, batch_targets).item())\n",
    "\n",
    "\n",
    "model, opt = get_model()\n",
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c06d3ff",
   "metadata": {},
   "source": [
    "## Random sampling\n",
    "\n",
    "What if we want our training set to be in a random order that differs every iteration (but keep the validations set the ssame)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9c18b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4], [47150, 9132, 33323, 34083, 44106])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "# Iterates over indices that  may or may not be shuffled\n",
    "class Sampler:\n",
    "    def __init__(self, dataset, shuffle=False):\n",
    "        self.N = len(dataset)\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        # List indices for the dataset\n",
    "        indices = list(range(self.N))\n",
    "\n",
    "        if self.shuffle:\n",
    "            random.shuffle(indices)\n",
    "\n",
    "        return iter(indices)\n",
    "\n",
    "\n",
    "list(Sampler(train_ds))[:5], list(Sampler(train_ds, True))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7d4c7def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[42329, 1416], [11506, 12809], [11167, 45051], [47512, 42783], [12792, 21287]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastcore.all as fc\n",
    "\n",
    "\n",
    "# Gets batches of the indices given by a sampler\n",
    "class BatchSampler:\n",
    "    def __init__(self, sampler, batch_size, drop_last=False):\n",
    "        fc.store_attr()  # Stores all inputs as members with same name\n",
    "\n",
    "    def __iter__(self):\n",
    "        for chunk in fc.chunked(iter(self.sampler), self.batch_size, drop_last=self.drop_last):\n",
    "            yield chunk\n",
    "\n",
    "\n",
    "# Batches of 2, randomised\n",
    "list(BatchSampler(Sampler(train_ds, True), 2))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d6bf2927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       "  tensor([4, 2, 2, 8, 0, 1, 4, 3, 7, 9, 8, 6, 6, 7, 4, 3, 0, 8, 3, 1, 4, 2, 2, 4,\n",
       "          0, 5, 6, 2, 1, 4, 1, 2, 4, 4, 3, 3, 3, 2, 9, 7, 2, 1, 0, 8, 1, 8, 1, 1,\n",
       "          3, 9, 4, 4, 3, 7, 3, 2, 1, 7, 0, 3, 0, 1, 1, 5])),\n",
       " torch.Size([64, 784]),\n",
       " torch.Size([64]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can update the DataLoader to use a BatchSampler rather than being told a batch size\n",
    "\n",
    "\n",
    "# We need a collation function to stack all of the Xs and all of the Ys together into tensors\n",
    "def collate(data):\n",
    "    data_x, data_y = zip(*data)\n",
    "    return torch.stack(data_x), torch.stack(data_y)\n",
    "\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, dataset, batch_sampler, collate_fn=collate):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __iter__(self):\n",
    "        yield from (self.collate_fn(self.dataset[i] for i in b) for b in self.batch_sampler)\n",
    "\n",
    "\n",
    "train_samp = BatchSampler(Sampler(train_ds, shuffle=True), batch_size)\n",
    "valid_samp = BatchSampler(Sampler(valid_ds, shuffle=False), batch_size)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_sampler=train_samp)\n",
    "valid_dl = DataLoader(valid_ds, batch_sampler=valid_samp)\n",
    "\n",
    "batch = next(iter(train_dl))\n",
    "batch, batch[0].shape, batch[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ce77b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.12259667366743088 acc:  0.9375\n",
      "loss: 0.020891010761260986 acc:  1.0\n",
      "loss: 0.19957318902015686 acc:  0.9375\n",
      "loss: 0.03951726853847504 acc:  1.0\n",
      "loss: 0.08813390880823135 acc:  1.0\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888bb796",
   "metadata": {},
   "source": [
    "### Multiprocessing DataLoader\n",
    "\n",
    "What if we want to run this in parallel to speed things up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ec87c883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([1, 1]))\n",
      "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([1, 0]))\n"
     ]
    }
   ],
   "source": [
    "# We want to be able to process something a bit like this but in parallel\n",
    "for o in map(train_ds.__getitem__, ([3, 6], [8, 1])):\n",
    "    print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "901a3059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.3553428649902344 acc:  0.875\n",
      "loss: 0.1931878924369812 acc:  0.9375\n",
      "loss: 0.08816784620285034 acc:  0.9375\n",
      "loss: 0.2127539962530136 acc:  0.9375\n",
      "loss: 0.021999867632985115 acc:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Pytorch gives us all of these and supports multiprocessing\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler, BatchSampler\n",
    "\n",
    "train_samp = BatchSampler(RandomSampler(train_ds), batch_size, drop_last=False)\n",
    "valid_samp = BatchSampler(SequentialSampler(valid_ds), batch_size, drop_last=False)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_sampler=train_samp, collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, batch_sampler=valid_samp, collate_fn=collate)\n",
    "\n",
    "model, opt = get_model()\n",
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fd786371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.6751914024353027 acc:  0.0\n",
      "loss: 1.8326674699783325 acc:  1.0\n",
      "loss: 2.142854928970337 acc:  0.0\n",
      "loss: 3.6747984886169434 acc:  0.0\n",
      "loss: 3.0272738933563232 acc:  0.0\n"
     ]
    }
   ],
   "source": [
    "# We can also pass a batch sampler as a sampler as we are able to index multiple things at once with no collate\n",
    "# pytorch kust autogens a BatchSampler for us\n",
    "train_dl = DataLoader(train_ds, sampler=train_samp)\n",
    "valid_dl = DataLoader(valid_ds, sampler=valid_samp)\n",
    "\n",
    "# As random sampling is so common, we can also just pass shuffle flags, and that dataset\n",
    "train_dl = DataLoader(train_ds, shuffle=True, drop_last=True)\n",
    "valid_dl = DataLoader(valid_ds, shuffle=False)\n",
    "\n",
    "model, opt = get_model()\n",
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1132e5d9",
   "metadata": {},
   "source": [
    "## Validation\n",
    "\n",
    "We've not done anything with the validation set yet. Lets update fit to take in a validation set. We'll print the validation loss for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b72d2981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        # Some layers behave differently during training and validation so we have to tell them\n",
    "        model.train()\n",
    "        for batch_inp, batch_targets in train_dl:\n",
    "            # Run the model\n",
    "            preds = model(batch_inp)\n",
    "            loss = loss_func(preds, batch_targets)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the weights\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "        # Now run the validation set\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            total_loss = 0.0\n",
    "            total_acc = 0.0\n",
    "            count = 0\n",
    "\n",
    "            for batch_inp, batch_targets in train_dl:\n",
    "                preds = model(batch_inp)\n",
    "\n",
    "                count += len(batch_inp)\n",
    "                total_loss += loss_func(preds, batch_targets).item() * len(batch_inp)\n",
    "                total_acc += accuracy(preds, batch_targets).item() * len(batch_inp)\n",
    "\n",
    "        total_loss /= count\n",
    "        total_acc /= count\n",
    "        print(f\"epoch: {epoch}, loss: {total_loss}, acc: {total_acc}\")\n",
    "\n",
    "    return total_loss, total_acc\n",
    "\n",
    "\n",
    "def get_dls(train_ds, valid_ds, batch_size, **kwargs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=batch_size, shuffle=True, **kwargs),\n",
    "        DataLoader(valid_ds, batch_size=batch_size * 2, **kwargs),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "404904cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.27256460088729856, acc: 0.9146\n",
      "epoch: 1, loss: 0.11975131210446358, acc: 0.9633\n",
      "epoch: 2, loss: 0.10393305077791214, acc: 0.96722\n",
      "epoch: 3, loss: 0.061809434617087246, acc: 0.98158\n",
      "epoch: 4, loss: 0.06857460128337145, acc: 0.9781\n"
     ]
    }
   ],
   "source": [
    "train_dl, valid_dl = get_dls(train_ds, valid_ds, 64)\n",
    "model, opt = get_model()\n",
    "loss, acc = fit(5, model, F.cross_entropy, opt, train_dl, valid_dl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
