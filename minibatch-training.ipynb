{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01c586f6",
   "metadata": {},
   "source": [
    "# Minibatch training\n",
    "\n",
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78aff7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the MNIST dataset\n",
    "import gzip\n",
    "import pickle\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import tensor\n",
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "MNIST_URL = \"https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/data/mnist.pkl.gz?raw=true\"\n",
    "\n",
    "data_path = Path(\"data/mnist\")\n",
    "data_path.mkdir(exist_ok=True)\n",
    "gz_path = data_path / \"mnist.pkl.gz\"\n",
    "\n",
    "mpl.rcParams[\"image.cmap\"] = \"gray\"\n",
    "\n",
    "if not gz_path.exists():\n",
    "    urlretrieve(MNIST_URL, gz_path)\n",
    "\n",
    "# File contains a tuple of tuples for the x and y, train and validation data\n",
    "# Images are 28x28\n",
    "with gzip.open(gz_path, \"rb\") as file:\n",
    "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(file, encoding=\"latin-1\")\n",
    "\n",
    "# Put into tensors\n",
    "x_train, y_train, x_valid, y_valid = map(tensor, [x_train, y_train, x_valid, y_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a61b49c",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea6932c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784, tensor(10))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets define some constants that describe the data\n",
    "n_examples, n_pixels = x_train.shape\n",
    "possible_values = y_train.max() + 1\n",
    "\n",
    "# How many nodes/activations/line thingys\n",
    "n_hidden = 50\n",
    "\n",
    "n_examples, n_pixels, possible_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e99425f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, n_hidden, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in, n_hidden), nn.ReLU(), nn.Linear(n_hidden, n_out)]\n",
    "\n",
    "    def __call__(self, inp):\n",
    "        res = inp\n",
    "        for layer in self.layers:\n",
    "            res = layer(res)\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10906723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(n_pixels, n_hidden, 10)\n",
    "pred = model(x_train)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0407cb79",
   "metadata": {},
   "source": [
    "## Cross entropy loss\n",
    "\n",
    "We need to improve our loss function as MSE doesn't make sense, the distance between incorrecd predictions doesn't indicate how good/bad the prediction is. For example if the target is 2, then 3 isnt a better guess than 9.\n",
    "\n",
    "We are outputting a pred for each possible number. As only one is possible at a time our targets are a one hot encoded matrix. If our targets are going to sum to 1, then it makes sense that our preds do too. We can calculate the softmax for each pred. Then for our loss func we compare the softmaxes to the 1 hot encoded targets. As we are 1 hot encoded we can ignore the other targets and just take the log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e266a35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1541, -2.4164, -2.2377,  ..., -2.2984, -2.3171, -2.4884],\n",
       "        [-2.2712, -2.2574, -2.1670,  ..., -2.2426, -2.4145, -2.4205],\n",
       "        [-2.1585, -2.3501, -2.1798,  ..., -2.3351, -2.3880, -2.3787],\n",
       "        ...,\n",
       "        [-2.1969, -2.3378, -2.2763,  ..., -2.2704, -2.3432, -2.4344],\n",
       "        [-2.1629, -2.3427, -2.1967,  ..., -2.2335, -2.3517, -2.4363],\n",
       "        [-2.2375, -2.3132, -2.1770,  ..., -2.2412, -2.3364, -2.4697]],\n",
       "       grad_fn=<LogBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def log_softmax(x):\n",
    "    return (x.exp() / (x.exp().sum(-1, keepdim=True))).log()\n",
    "\n",
    "\n",
    "log_softmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a44a84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1541, -2.4164, -2.2377,  ..., -2.2984, -2.3171, -2.4884],\n",
       "        [-2.2712, -2.2574, -2.1670,  ..., -2.2426, -2.4145, -2.4205],\n",
       "        [-2.1585, -2.3501, -2.1798,  ..., -2.3351, -2.3880, -2.3787],\n",
       "        ...,\n",
       "        [-2.1969, -2.3378, -2.2763,  ..., -2.2704, -2.3432, -2.4344],\n",
       "        [-2.1629, -2.3427, -2.1967,  ..., -2.2335, -2.3517, -2.4363],\n",
       "        [-2.2375, -2.3132, -2.1770,  ..., -2.2412, -2.3364, -2.4697]],\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As log(a/b) = log(a) - log(b), we can simplify things to:\n",
    "\n",
    "\n",
    "def log_softmax(x):\n",
    "    return x - x.exp().sum(-1, keepdim=True).log()\n",
    "\n",
    "\n",
    "log_softmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "440b7db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1083, -0.1540,  0.0246,  ..., -0.0360, -0.0547, -0.2261],\n",
       "        [ 0.0443,  0.0581,  0.1486,  ...,  0.0729, -0.0989, -0.1049],\n",
       "        [ 0.1757, -0.0158,  0.1544,  ..., -0.0008, -0.0538, -0.0445],\n",
       "        ...,\n",
       "        [ 0.1097, -0.0312,  0.0303,  ...,  0.0362, -0.0366, -0.1278],\n",
       "        [ 0.1225, -0.0573,  0.0887,  ...,  0.0519, -0.0663, -0.1509],\n",
       "        [ 0.0573, -0.0185,  0.1177,  ...,  0.0535, -0.0417, -0.1750]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Its possible for the sum of the exponentials of big activations to overflow\n",
    "# pytorch uses some tricks to solve this for use in one function\n",
    "def log_softmax(x):\n",
    "    return x - x.logsumexp(-1, keepdim=True)\n",
    "\n",
    "\n",
    "sm_pred = log_softmax(pred)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4f5c4e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4, 1, 9])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How do we index into the preds we want\n",
    "# The y values tell us targets, which are also the index\n",
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f242e903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.4615, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So for each i we want row i and col y_train[i]. eg for pred at row 0\n",
    "sm_pred[0, y_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8258835d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.4615, -2.2712, -2.2086,  ..., -2.3432, -2.2861, -2.3364],\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can do this for all of them like this\n",
    "sm_pred[range(y_train.shape[0]), y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53da62e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3122, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So our cross entropy loss function looks like this\n",
    "def nll(inp, target):\n",
    "    return -inp[range(target.shape[0]), target].mean()\n",
    "\n",
    "\n",
    "loss = nll(sm_pred, y_train)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36a9df11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3122, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pytorch gives us both of these functions, NLL = negative log likelihood\n",
    "F.nll_loss(F.log_softmax(pred, -1), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ad1ea7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3122, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And a cross entropy function to do it all in one\n",
    "F.cross_entropy(pred, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0106d075",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e346551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.1083, -0.1540,  0.0246,  0.0735,  0.1174, -0.1992, -0.1280, -0.0360,\n",
       "         -0.0547, -0.2261], grad_fn=<SelectBackward0>),\n",
       " torch.Size([64, 10]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func = F.cross_entropy\n",
    "batch_size = 64\n",
    "\n",
    "# First we would run a minibatch\n",
    "mini_batch = x_train[0:batch_size]\n",
    "mini_batch_y = y_train[0:batch_size]\n",
    "\n",
    "preds = model(mini_batch)\n",
    "preds[0], preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d6d39d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3164, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then we would calculate the loss\n",
    "loss_func(preds, mini_batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e53a274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 2, 0, 0, 2, 3, 2, 2, 3, 4, 0, 3, 0, 2, 2, 0, 0, 4, 0, 3, 0, 0, 3, 0,\n",
       "        3, 0, 3, 0, 0, 4, 4, 4, 2, 3, 4, 4, 2, 2, 3, 3, 2, 0, 3, 0, 3, 2, 0, 4,\n",
       "        3, 4, 3, 0, 2, 4, 2, 2, 0, 3, 0, 4, 2, 3, 2, 7])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each of our predictions what did we predict, we need the highest number from each set of preds and get its index\n",
    "preds.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13b7fe47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False,  True,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False,  True, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False,  True, False, False, False, False, False,\n",
       "         True,  True, False,  True, False, False,  True, False, False, False,\n",
       "        False, False, False, False])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see which we got correct\n",
    "preds.argmax(dim=1) == mini_batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aff29583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1094)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use it to calculate accuracy, this isnt needed for the NN but helps us understand whats going on\n",
    "def accuracy(out, targets):\n",
    "    return (out.argmax(dim=1) == targets).float().mean()\n",
    "\n",
    "\n",
    "accuracy(preds, mini_batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21fb07ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.3164234161376953 acc:  0.109375\n",
      "loss: 0.14103679358959198 acc:  0.953125\n",
      "loss: 0.1338021159172058 acc:  0.953125\n",
      "loss: 0.09388265013694763 acc:  0.96875\n",
      "loss: 0.06046620383858681 acc:  0.96875\n"
     ]
    }
   ],
   "source": [
    "# Now we want to do all of the batches for a bunch of epochs, updating the weights each time\n",
    "import torch\n",
    "\n",
    "lr = 0.5\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch_start in range(0, n_examples, batch_size):\n",
    "        # Get the slice\n",
    "        sl = slice(batch_start, min(n_examples, batch_start + batch_size))\n",
    "\n",
    "        batch_inp = x_train[sl]\n",
    "        batch_targets = y_train[sl]\n",
    "\n",
    "        # Run the model\n",
    "        preds = model(batch_inp)\n",
    "        loss = loss_func(preds, batch_targets)\n",
    "\n",
    "        if batch_start == 0:\n",
    "            print(\"loss:\", loss.item(), \"acc: \", accuracy(preds, batch_targets).item())\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        with torch.no_grad():\n",
    "            for layer in model.layers:\n",
    "                if hasattr(layer, \"weight\"):\n",
    "                    layer.weight -= layer.weight.grad * lr\n",
    "                    layer.bias -= layer.bias.grad * lr\n",
    "                    layer.weight.grad.zero_()\n",
    "                    layer.bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8dcc68",
   "metadata": {},
   "source": [
    "## Parameters and optim\n",
    "\n",
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "536fee2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Module(\n",
       "   (foo): Linear(in_features=3, out_features=4, bias=True)\n",
       " ),\n",
       " [('foo', Linear(in_features=3, out_features=4, bias=True))],\n",
       " [Parameter containing:\n",
       "  tensor([[-0.2638, -0.4812, -0.5154],\n",
       "          [-0.0276, -0.3032,  0.1277],\n",
       "          [ 0.5214, -0.3499,  0.0212],\n",
       "          [ 0.2150,  0.5617,  0.2342]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0399, -0.1333,  0.3603,  0.4867], requires_grad=True)])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = nn.Module()\n",
    "m1.foo = nn.Linear(3, 4)\n",
    "\n",
    "# Notice that the Module can automatically track all of the parameters in the\n",
    "# layer that is assigned to it, how does that work?\n",
    "m1, list(m1.named_children()), list(m1.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c92ccbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(MLP(\n",
       "   (l1): Linear(in_features=784, out_features=50, bias=True)\n",
       "   (l2): Linear(in_features=50, out_features=10, bias=True)\n",
       "   (relu): ReLU()\n",
       " ),\n",
       " Linear(in_features=784, out_features=50, bias=True),\n",
       " [('l1', Linear(in_features=784, out_features=50, bias=True)),\n",
       "  ('l2', Linear(in_features=50, out_features=10, bias=True)),\n",
       "  ('relu', ReLU())],\n",
       " [torch.Size([50, 784]),\n",
       "  torch.Size([50]),\n",
       "  torch.Size([10, 50]),\n",
       "  torch.Size([10])])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_in, n_hidden, n_out):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_in, n_hidden)\n",
    "        self.l2 = nn.Linear(n_hidden, n_out)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.l2(self.relu(self.l1(x)))\n",
    "\n",
    "\n",
    "# We normally use Module by inheriting from it and assigning it a bynch of layers\n",
    "\n",
    "model = MLP(n_pixels, n_hidden, 10)\n",
    "model, model.l1, list(model.named_children()), list(map(lambda x: x.shape, model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a18d00e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.313939332962036 acc:  0.140625\n",
      "loss: 0.12737786769866943 acc:  0.96875\n",
      "loss: 0.17124103009700775 acc:  0.9375\n",
      "loss: 0.10446500033140182 acc:  0.953125\n",
      "loss: 0.08941523730754852 acc:  0.953125\n"
     ]
    }
   ],
   "source": [
    "# So already we can rewrite our loop knowing we can just get all of the params from the model\n",
    "\n",
    "\n",
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for batch_start in range(0, n_examples, batch_size):\n",
    "            # Get the slice\n",
    "            sl = slice(batch_start, min(n_examples, batch_start + batch_size))\n",
    "\n",
    "            batch_inp = x_train[sl]\n",
    "            batch_targets = y_train[sl]\n",
    "\n",
    "            # Run the model\n",
    "            preds = model(batch_inp)\n",
    "            loss = loss_func(preds, batch_targets)\n",
    "\n",
    "            if batch_start == 0:\n",
    "                print(\"loss:\", loss.item(), \"acc: \", accuracy(preds, batch_targets).item())\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the weights\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p -= p.grad * lr\n",
    "                model.zero_grad()\n",
    "\n",
    "\n",
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "248c8cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': Linear(in_features=784, out_features=50, bias=True), 'l2': Linear(in_features=50, out_features=10, bias=True)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's how we would implement this if nn.Module didn't exist\n",
    "class MyModule:\n",
    "    def __init__(self, n_in, n_hidden, n_out):\n",
    "        self._modules = {}\n",
    "        self.l1 = nn.Linear(n_in, n_hidden)\n",
    "        self.l2 = nn.Linear(n_hidden, n_out)\n",
    "\n",
    "    # We hook into setattr and update _modules when some sets something new\n",
    "    def __setattr__(self, key, value):\n",
    "        if not key.startswith(\"_\"):\n",
    "            self._modules[key] = value\n",
    "        super().__setattr__(key, value)\n",
    "\n",
    "    # Print modules\n",
    "    def __repr__(self):\n",
    "        return f\"{self._modules}\"\n",
    "\n",
    "    # Generate the parameters of every module\n",
    "    def parameters(self):\n",
    "        for mod in self.modules.values():\n",
    "            for p in mod.parameters():\n",
    "                yield p\n",
    "\n",
    "\n",
    "myM = MyModule(n_pixels, n_hidden, 10)\n",
    "myM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f833b6a",
   "metadata": {},
   "source": [
    "### Registering modules\n",
    "\n",
    "We previously stored all our layers in a .layers member. How would we do that with nn.module. You can manually add layers using `add_module`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "887f0adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (layer_0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (layer_1): ReLU()\n",
       "  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "\n",
    "        for idx, layer in enumerate(self.layers):\n",
    "            self.add_module(f\"layer_{idx}\", layer)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return reduce(lambda val, layer: layer(val), self.layers, x)\n",
    "\n",
    "\n",
    "layers = [nn.Linear(n_pixels, n_hidden), nn.ReLU(), nn.Linear(n_hidden, 10)]\n",
    "model = Model(layers)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe6fd71",
   "metadata": {},
   "source": [
    "#### nn.ModuleList\n",
    "\n",
    "`nn.ModuleList` does this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28abe8d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialModel(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SequentialModel(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = SequentialModel(layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15d1f817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.2983474731445312 acc:  0.125\n",
      "loss: 0.162628173828125 acc:  0.9375\n",
      "loss: 0.09918573498725891 acc:  0.96875\n",
      "loss: 0.08054450154304504 acc:  0.96875\n",
      "loss: 0.05816757306456566 acc:  0.96875\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71358a37",
   "metadata": {},
   "source": [
    "#### nn.Sequential\n",
    "\n",
    "`nn.Sequential` already exists and does the lot for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "093cbb0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = [nn.Linear(n_pixels, n_hidden), nn.ReLU(), nn.Linear(n_hidden, 10)]\n",
    "model = nn.Sequential(*layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5aa655c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.303898811340332 acc:  0.0625\n",
      "loss: 0.11739269644021988 acc:  0.96875\n",
      "loss: 0.07968293130397797 acc:  0.96875\n",
      "loss: 0.08661330491304398 acc:  0.96875\n",
      "loss: 0.06353913247585297 acc:  0.984375\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a76e0a",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26fa63ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could put our optimisation steps into a class\n",
    "\n",
    "\n",
    "class Optimizer:\n",
    "    def __init__(self, params, lr=0.5):\n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "\n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params:\n",
    "                p -= p.grad * self.lr\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.params:\n",
    "            p.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2cd9b073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.2822203636169434 acc:  0.15625\n",
      "loss: 0.1406371295452118 acc:  0.9375\n",
      "loss: 0.11584998667240143 acc:  0.953125\n",
      "loss: 0.15190747380256653 acc:  0.953125\n",
      "loss: 0.17144279181957245 acc:  0.96875\n"
     ]
    }
   ],
   "source": [
    "layers = [nn.Linear(n_pixels, n_hidden), nn.ReLU(), nn.Linear(n_hidden, 10)]\n",
    "model = nn.Sequential(*layers)\n",
    "opt = Optimizer(model.parameters())\n",
    "\n",
    "\n",
    "# And now our training loop will look like this\n",
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for batch_start in range(0, n_examples, batch_size):\n",
    "            # Get the slice\n",
    "            sl = slice(batch_start, min(n_examples, batch_start + batch_size))\n",
    "\n",
    "            batch_inp = x_train[sl]\n",
    "            batch_targets = y_train[sl]\n",
    "\n",
    "            # Run the model\n",
    "            preds = model(batch_inp)\n",
    "            loss = loss_func(preds, batch_targets)\n",
    "\n",
    "            if batch_start == 0:\n",
    "                print(\"loss:\", loss.item(), \"acc: \", accuracy(preds, batch_targets).item())\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the weights\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "\n",
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "098f1a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.292577028274536 acc:  0.109375\n",
      "loss: 0.1324172019958496 acc:  0.953125\n",
      "loss: 0.08873302489519119 acc:  0.96875\n",
      "loss: 0.058555759489536285 acc:  0.984375\n",
      "loss: 0.032626863569021225 acc:  1.0\n"
     ]
    }
   ],
   "source": [
    "# pytorch gives use this as well\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    layers = [nn.Linear(n_pixels, n_hidden), nn.ReLU(), nn.Linear(n_hidden, 10)]\n",
    "    model = nn.Sequential(*layers)\n",
    "    opt = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    return model, opt\n",
    "\n",
    "\n",
    "model, opt = get_model()\n",
    "\n",
    "\n",
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for batch_start in range(0, n_examples, batch_size):\n",
    "            # Get the slice\n",
    "            sl = slice(batch_start, min(n_examples, batch_start + batch_size))\n",
    "\n",
    "            batch_inp = x_train[sl]\n",
    "            batch_targets = y_train[sl]\n",
    "\n",
    "            # Run the model\n",
    "            preds = model(batch_inp)\n",
    "            loss = loss_func(preds, batch_targets)\n",
    "\n",
    "            if batch_start == 0:\n",
    "                print(\"loss:\", loss.item(), \"acc: \", accuracy(preds, batch_targets).item())\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the weights\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "\n",
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4894616",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader\n",
    "\n",
    "What if we want to more easily iterate through minimatches and x/y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6c44b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10000)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.x[i], self.y[i]\n",
    "\n",
    "\n",
    "train_ds = Dataset(x_train, y_train)\n",
    "valid_ds = Dataset(x_valid, y_valid)\n",
    "\n",
    "len(train_ds), len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df66e33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       "  tensor([5, 0, 4, 1, 9])),\n",
       " torch.Size([5, 784]),\n",
       " torch.Size([5]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# __getitem__ works with tensors\n",
    "train_ds[0:5], train_ds[0:5][0].shape, train_ds[0:5][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce3038f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.299999237060547 acc:  0.078125\n",
      "loss: 0.12770475447177887 acc:  0.9375\n",
      "loss: 0.15836617350578308 acc:  0.921875\n",
      "loss: 0.08538192510604858 acc:  0.96875\n",
      "loss: 0.03836856409907341 acc:  0.984375\n"
     ]
    }
   ],
   "source": [
    "# We can now simplify the slicing\n",
    "\n",
    "\n",
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for batch_start in range(0, n_examples, batch_size):\n",
    "            # Get the slice\n",
    "            sl = slice(batch_start, min(n_examples, batch_start + batch_size))\n",
    "\n",
    "            batch_inp, batch_targets = train_ds[batch_start : min(n_examples, batch_start + batch_size)]\n",
    "\n",
    "            # Run the model\n",
    "            preds = model(batch_inp)\n",
    "            loss = loss_func(preds, batch_targets)\n",
    "\n",
    "            if batch_start == 0:\n",
    "                print(\"loss:\", loss.item(), \"acc: \", accuracy(preds, batch_targets).item())\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the weights\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "\n",
    "model, opt = get_model()\n",
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a3f74d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A DataLoader is an iterator that will help us with looping over the minibatches\n",
    "\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, dataset, batch_size):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch_start in range(0, len(self.dataset), batch_size):\n",
    "            yield self.dataset[batch_start : batch_start + self.batch_size]\n",
    "\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size)\n",
    "valid_dl = DataLoader(valid_ds, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "16ef6ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.33352193236351013 acc:  0.9375\n",
      "loss: 0.0953538790345192 acc:  0.9375\n",
      "loss: 0.037897951900959015 acc:  1.0\n",
      "loss: 0.030555281788110733 acc:  1.0\n",
      "loss: 0.01890832744538784 acc:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Now we can remove the slicing form our loop\n",
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for batch_inp, batch_targets in train_dl:\n",
    "            # Run the model\n",
    "            preds = model(batch_inp)\n",
    "            loss = loss_func(preds, batch_targets)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the weights\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        print(\"loss:\", loss.item(), \"acc: \", accuracy(preds, batch_targets).item())\n",
    "\n",
    "\n",
    "model, opt = get_model()\n",
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0577afc8",
   "metadata": {},
   "source": [
    "## Random sampling\n",
    "\n",
    "What if we want our training set to be in a random order that differs every iteration (but keep the validations set the ssame)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fecafef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4], [33876, 20379, 41070, 19168, 38762])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "# Iterates over indices that  may or may not be shuffled\n",
    "class Sampler:\n",
    "    def __init__(self, dataset, shuffle=False):\n",
    "        self.N = len(dataset)\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        # List indices for the dataset\n",
    "        indices = list(range(self.N))\n",
    "\n",
    "        if self.shuffle:\n",
    "            random.shuffle(indices)\n",
    "\n",
    "        return iter(indices)\n",
    "\n",
    "\n",
    "list(Sampler(train_ds))[:5], list(Sampler(train_ds, True))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9b1c6518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3318, 31199], [8674, 46640], [35082, 21457], [2137, 48900], [38909, 27076]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastcore.all as fc\n",
    "\n",
    "\n",
    "# Gets batches of the indices given by a sampler\n",
    "class BatchSampler:\n",
    "    def __init__(self, sampler, batch_size, drop_last=False):\n",
    "        fc.store_attr()  # Stores all inputs as members with same name\n",
    "\n",
    "    def __iter__(self):\n",
    "        for chunk in fc.chunked(iter(self.sampler), self.batch_size, drop_last=self.drop_last):\n",
    "            yield chunk\n",
    "\n",
    "\n",
    "# Batches of 2, randomised\n",
    "list(BatchSampler(Sampler(train_ds, True), 2))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "02f5b5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       "  tensor([2, 9, 9, 5, 1, 8, 6, 1, 6, 0, 6, 7, 6, 7, 0, 9, 6, 7, 3, 0, 8, 8, 0, 6,\n",
       "          2, 4, 8, 4, 4, 9, 4, 8, 2, 9, 0, 7, 9, 9, 0, 1, 2, 3, 7, 9, 6, 0, 5, 3,\n",
       "          5, 8, 7, 6, 5, 2, 0, 1, 1, 9, 2, 4, 3, 5, 1, 3])),\n",
       " torch.Size([64, 784]),\n",
       " torch.Size([64]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can update the DataLoader to use a BatchSampler rather than being told a batch size\n",
    "\n",
    "\n",
    "# We need a collation function to stack all of the Xs and all of the Ys together into tensors\n",
    "def collate(data):\n",
    "    data_x, data_y = zip(*data)\n",
    "    return torch.stack(data_x), torch.stack(data_y)\n",
    "\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, dataset, batch_sampler, collate_fn=collate):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __iter__(self):\n",
    "        yield from (self.collate_fn(self.dataset[i] for i in b) for b in self.batch_sampler)\n",
    "\n",
    "\n",
    "train_samp = BatchSampler(Sampler(train_ds, shuffle=True), batch_size)\n",
    "valid_samp = BatchSampler(Sampler(valid_ds, shuffle=False), batch_size)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_sampler=train_samp)\n",
    "valid_dl = DataLoader(valid_ds, batch_sampler=valid_samp)\n",
    "\n",
    "batch = next(iter(train_dl))\n",
    "batch, batch[0].shape, batch[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b802a9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.23163193464279175 acc:  0.9375\n",
      "loss: 0.021201523020863533 acc:  1.0\n",
      "loss: 0.08637157082557678 acc:  1.0\n",
      "loss: 0.007034916430711746 acc:  1.0\n",
      "loss: 0.3597562313079834 acc:  0.8125\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136fec3b",
   "metadata": {},
   "source": [
    "### Multiprocessing DataLoader\n",
    "\n",
    "What if we want to run this in parallel to speed things up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a56111f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([1, 1]))\n",
      "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([1, 0]))\n"
     ]
    }
   ],
   "source": [
    "# We want to be able to process something a bit like this but in parallel\n",
    "for o in map(train_ds.__getitem__, ([3, 6], [8, 1])):\n",
    "    print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "04964cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.175296351313591 acc:  0.9375\n",
      "loss: 0.05440215766429901 acc:  1.0\n",
      "loss: 0.13612455129623413 acc:  0.9375\n",
      "loss: 0.04176424816250801 acc:  1.0\n",
      "loss: 0.0018899767892435193 acc:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Pytorch gives us all of these and supports multiprocessing\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler, BatchSampler\n",
    "\n",
    "train_samp = BatchSampler(RandomSampler(train_ds), batch_size, drop_last=False)\n",
    "valid_samp = BatchSampler(SequentialSampler(valid_ds), batch_size, drop_last=False)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_sampler=train_samp, collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, batch_sampler=valid_samp, collate_fn=collate)\n",
    "\n",
    "model, opt = get_model()\n",
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f6d7f06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also pass a batch sampler as a sampler as we are able to index multiple things at once with no collate\n",
    "# pytorch kust autogens a BatchSampler for us\n",
    "train_dl = DataLoader(train_ds, sampler=train_samp)\n",
    "valid_dl = DataLoader(valid_ds, sampler=valid_samp)\n",
    "\n",
    "# As random sampling is so common, we can also just pass shuffle flags, and that dataset\n",
    "train_dl = DataLoader(train_ds, shuffle=True, drop_last=True)\n",
    "valid_dl = DataLoader(valid_ds, shuffle=False)\n",
    "\n",
    "model, opt = get_model()\n",
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a05c22d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
