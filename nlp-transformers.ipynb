{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "489afbac",
   "metadata": {},
   "source": [
    "# NLP\n",
    "\n",
    "NLP using huggingface transformers.\n",
    "\n",
    "## Pretraining and finetuning neural nets\n",
    "\n",
    "A pretrained model is bunch of parameters that have already been fit. Some of them we are confident about where they should be and some of them less so.\n",
    "\n",
    "Finetuning is working out the ones we had less of an idea about and wiggling the others a bit.\n",
    "\n",
    "### ULMFit\n",
    "\n",
    "First proposed by ULMFit. Used RNN not transformers.\n",
    "\n",
    "Wikitext 103 - Language Model (predicts the next word of wikipedia) - requires \"understanding\" of language structure, the world, maths etc. Got to about 30% accuracy.\n",
    "\n",
    "IMDb - Language model (use Wiktext as pretrained model to train same thing on IMDb)\n",
    "\n",
    "IMDB Classifier - Classifier - fine tune IMDb language model to detect sentiment.\n",
    "\n",
    "### Transformers\n",
    "\n",
    "Not structured the same so need a different but similar idea:\n",
    "\n",
    "Take a chunk of text and ask model to detect/predict the missing words.\n",
    "\n",
    "## NLP\n",
    "\n",
    "Most common/useful/practical area for NLP is classification (sentiment analysis, author id, topics etc.).\n",
    "\n",
    "One example is [U.S. Patent Phrase to Phrase Matching](https://www.kaggle.com/competitions/us-patent-phrase-to-phrase-matching/overview)\n",
    "\n",
    "The task is comparing two words or short phrases and scoring them basdd on if they are similar or not, basaed on which patent class they were used in. \n",
    "\n",
    "```\n",
    "1    == Very close match\n",
    "0.75 == Close synonym (eg. “mobile phone” vs. “cellphone”)\n",
    "0.5  == Synonyms which don’t have the same meaning (eg. \"abatement\" and \"eliminating process\")\n",
    "0.25 == Somewhat related,\n",
    "0    == Unrelated\n",
    "```\n",
    "\n",
    "For this to be a categorisation problem just consider each score as a category.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de474ce3",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40beb93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "iskaggle = os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1c27c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"data/us-patent-phrase-to-phrase-matching\")\n",
    "if iskaggle and not path.exists():\n",
    "    path = Path(\"../input/us-patent-phrase-to-phrase-matching\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd5ee1d",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f936ffa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37d61fd2272659b1</td>\n",
       "      <td>abatement</td>\n",
       "      <td>abatement of pollution</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7b9652b17b68b7a4</td>\n",
       "      <td>abatement</td>\n",
       "      <td>act of abating</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36d72442aefd8232</td>\n",
       "      <td>abatement</td>\n",
       "      <td>active catalyst</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5296b0c19e1ce60e</td>\n",
       "      <td>abatement</td>\n",
       "      <td>eliminating process</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54c1e3b9184cb5b6</td>\n",
       "      <td>abatement</td>\n",
       "      <td>forest region</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36468</th>\n",
       "      <td>8e1386cbefd7f245</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden article</td>\n",
       "      <td>B44</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36469</th>\n",
       "      <td>42d9e032d1cd3242</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden box</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36470</th>\n",
       "      <td>208654ccb9e14fa3</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden handle</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36471</th>\n",
       "      <td>756ec035e694722b</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden material</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36472</th>\n",
       "      <td>8d135da0b55b8c88</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden substrate</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36473 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id        anchor                  target context  score\n",
       "0      37d61fd2272659b1     abatement  abatement of pollution     A47   0.50\n",
       "1      7b9652b17b68b7a4     abatement          act of abating     A47   0.75\n",
       "2      36d72442aefd8232     abatement         active catalyst     A47   0.25\n",
       "3      5296b0c19e1ce60e     abatement     eliminating process     A47   0.50\n",
       "4      54c1e3b9184cb5b6     abatement           forest region     A47   0.00\n",
       "...                 ...           ...                     ...     ...    ...\n",
       "36468  8e1386cbefd7f245  wood article          wooden article     B44   1.00\n",
       "36469  42d9e032d1cd3242  wood article              wooden box     B44   0.50\n",
       "36470  208654ccb9e14fa3  wood article           wooden handle     B44   0.50\n",
       "36471  756ec035e694722b  wood article         wooden material     B44   0.75\n",
       "36472  8d135da0b55b8c88  wood article        wooden substrate     B44   0.50\n",
       "\n",
       "[36473 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_frame = pd.read_csv(path / \"train.csv\")\n",
    "train_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6a4b7fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>36473</td>\n",
       "      <td>733</td>\n",
       "      <td>29340</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>37d61fd2272659b1</td>\n",
       "      <td>component composite coating</td>\n",
       "      <td>composition</td>\n",
       "      <td>H01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>24</td>\n",
       "      <td>2186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                       anchor       target context\n",
       "count              36473                        36473        36473   36473\n",
       "unique             36473                          733        29340     106\n",
       "top     37d61fd2272659b1  component composite coating  composition     H01\n",
       "freq                   1                          152           24    2186"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_frame.describe(include=\"object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65bc06d",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3d5c4f",
   "metadata": {},
   "source": [
    "We need to provide input to the model in some format, lets shove it into a semi-structured string in the form:\n",
    "    \n",
    "`TEXT1: {context}; TEXT2: {target}; ANC1: {anchor};`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02af8531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    TEXT1: A47; TEXT2: abatement of pollution; ANC...\n",
       "1    TEXT1: A47; TEXT2: act of abating; ANC1: abate...\n",
       "2    TEXT1: A47; TEXT2: active catalyst; ANC1: abat...\n",
       "3    TEXT1: A47; TEXT2: eliminating process; ANC1: ...\n",
       "4    TEXT1: A47; TEXT2: forest region; ANC1: abatem...\n",
       "Name: input, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_frame[\"input\"] = (\n",
    "    \"TEXT1: \" + train_frame.context + \"; TEXT2: \" + train_frame.target + \"; ANC1: \" + train_frame.anchor + \";\"\n",
    ")\n",
    "train_frame.input.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ce1ebf",
   "metadata": {},
   "source": [
    "## Tokenisation and numericalisation\n",
    "\n",
    "- Tokenisation - Some languages dont have words so we split into subwords (\"tokens\").\n",
    "- Numericalisation - convert each token into a number for our model.\n",
    "\n",
    "We'll use huggingface DataSets. This is what huggingface transformers uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c83514bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'anchor', 'target', 'context', 'score', 'input'],\n",
       "    num_rows: 36473\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_frame)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e818329",
   "metadata": {},
   "source": [
    "We need to pick a model as tokenisation/numericalisation is a bit different for each pretrained model. We need to do the same thing as the preople who trained the model did so we get the same inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72d92ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can use -small or -large\n",
    "model_nm = \"microsoft/deberta-v3-small\"\n",
    "\n",
    "if iskaggle:\n",
    "    model_nm = \"../input/debertav3small/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1c28298",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# AutoTokenizer creates an appropriate tokeniser for the model\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(model_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fea6c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁Hello',\n",
       " ',',\n",
       " '▁this',\n",
       " '▁is',\n",
       " '▁a',\n",
       " '▁sentence',\n",
       " '▁WITH',\n",
       " 'SOME',\n",
       " 'WORD',\n",
       " 's',\n",
       " '▁that',\n",
       " '▁will',\n",
       " '▁be',\n",
       " '▁to',\n",
       " 'k',\n",
       " \"'\",\n",
       " 'ed',\n",
       " '▁into',\n",
       " '▁sub',\n",
       " '-',\n",
       " 'words',\n",
       " ',',\n",
       " '▁FUN',\n",
       " '!']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example of the tokenisation\n",
    "tok.tokenize(\"Hello, this is a sentence WITHSOMEWORDs that will be tok'ed into sub-words, FUN!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9991afdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to tokenise our inputs\n",
    "\n",
    "\n",
    "def tok_fn(x):\n",
    "    return tok(x[\"input\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9964c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52851ed2b20e49598c08f7ea24e909a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/36473 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'anchor', 'target', 'context', 'score', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 36473\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run it on the training data\n",
    "tok_train = train_dataset.map(tok_fn, batched=True)\n",
    "tok_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b6429a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We now have a new input_ids field, this is a list of numbers that maps to words in the vocab, for example\n",
    "tok.vocab[\"▁of\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b31b1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'anchor', 'target', 'context', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 36473\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need the labels (categories) for our training input, transformers assumes its called labels, but its currently called score\n",
    "tok_train = tok_train.rename_columns({\"score\": \"labels\"})\n",
    "tok_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6651ba0",
   "metadata": {},
   "source": [
    "## Test/validation data sets\n",
    "\n",
    "We also have a test set. This is to help us identify overfitting/overfitting.\n",
    "\n",
    "* Underfit - not enough complexity in the model to represent things. Systematically biased. Training data will not fit well.\n",
    "* Overfit - too much complexity in the model, represents our training set but not our general problem. Test/validation data will not fit well.\n",
    "\n",
    "We need to be careful of how we create test/validation data. We could accidentally create a set that still matches an overfitted model. For example a uniform distribution of points from a timeseries dataset (bad) vs taking the last 1 week (better).\n",
    "\n",
    "So we need a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e987500a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'anchor', 'target', 'context', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 27354\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'anchor', 'target', 'context', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 9119\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transformers can take a dataset and split it into two\n",
    "# Note, its a bit confusing as our validation set is called test\n",
    "\n",
    "dataset_dict = tok_train.train_test_split(0.25)\n",
    "dataset_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1354cf",
   "metadata": {},
   "source": [
    "Lets also load the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f970b6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37603abbde85410da20aa5bf74d3afd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/36 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'anchor', 'target', 'context', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 36\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_frame = pd.read_csv(path / \"test.csv\")\n",
    "test_frame[\"input\"] = (\n",
    "    \"TEXT1: \" + test_frame.context + \"; TEXT2: \" + test_frame.target + \"; ANC1: \" + test_frame.anchor + \";\"\n",
    ")\n",
    "\n",
    "test_dataset = Dataset.from_pandas(test_frame).map(tok_fn, batched=True)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e7fc04",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "Measurements we are interseted in maximising or minimising.\n",
    "\n",
    "This kaggle comp measures based on the [Pearson correlation coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient)\n",
    "\n",
    "Note that in the real world optimising for metrics is a double edged sword. You have to optimise for something, so you need metrics, but any given metric will be unlikely to represent to complexity of performance in the real world. AI can sometimes be a bit too good at optimising for a metric rather than its actual job.\n",
    "\n",
    "Lets define our own correlation function to use as the compute metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a09a61d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def corr(x, y):\n",
    "    return np.corrcoef(x, y)[0][1]\n",
    "\n",
    "\n",
    "def corr_d(eval_pred):\n",
    "    return {\"pearson\": corr(*eval_pred)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015ceed9",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1cf0595",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['pooler.dense.bias', 'classifier.bias', 'classifier.weight', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "bs = 128\n",
    "epochs = 10\n",
    "lr = 8e-5\n",
    "\n",
    "# Arguments for the trainer\n",
    "args = TrainingArguments(\n",
    "    \"outputs\",\n",
    "    learning_rate=lr,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    fp16=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=bs,\n",
    "    per_device_eval_batch_size=bs * 2,\n",
    "    num_train_epochs=epochs,\n",
    "    weight_decay=0.01,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# Create the model and the trainer\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=1)\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=dataset_dict[\"train\"],\n",
    "    eval_dataset=dataset_dict[\"test\"],\n",
    "    tokenizer=tok,\n",
    "    compute_metrics=corr_d,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91c6d1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2140' max='2140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2140/2140 06:51, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.027138</td>\n",
       "      <td>0.795760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.022707</td>\n",
       "      <td>0.825082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.036800</td>\n",
       "      <td>0.024571</td>\n",
       "      <td>0.826926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.036800</td>\n",
       "      <td>0.020292</td>\n",
       "      <td>0.838661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>0.023074</td>\n",
       "      <td>0.839770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>0.021925</td>\n",
       "      <td>0.842033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>0.021572</td>\n",
       "      <td>0.841824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.021221</td>\n",
       "      <td>0.843823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.021251</td>\n",
       "      <td>0.843621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.021292</td>\n",
       "      <td>0.843733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2140, training_loss=0.015394991691981521, metrics={'train_runtime': 412.252, 'train_samples_per_second': 663.526, 'train_steps_per_second': 5.191, 'total_flos': 1867646572494840.0, 'train_loss': 0.015394991691981521, 'epoch': 10.0})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dedae76",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b858e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.42993164],\n",
       "       [ 0.75341797],\n",
       "       [ 0.51318359],\n",
       "       [ 0.24438477],\n",
       "       [-0.02354431],\n",
       "       [ 0.50439453],\n",
       "       [ 0.45068359],\n",
       "       [-0.01178741],\n",
       "       [ 0.28466797],\n",
       "       [ 1.04101562],\n",
       "       [ 0.25048828],\n",
       "       [ 0.22973633],\n",
       "       [ 0.83105469],\n",
       "       [ 0.84277344],\n",
       "       [ 0.76367188],\n",
       "       [ 0.41601562],\n",
       "       [ 0.30200195],\n",
       "       [-0.03231812],\n",
       "       [ 0.56152344],\n",
       "       [ 0.43774414],\n",
       "       [ 0.53417969],\n",
       "       [ 0.24853516],\n",
       "       [ 0.16418457],\n",
       "       [ 0.22900391],\n",
       "       [ 0.58935547],\n",
       "       [-0.01359558],\n",
       "       [-0.02694702],\n",
       "       [-0.02174377],\n",
       "       [-0.01811218],\n",
       "       [ 0.65136719],\n",
       "       [ 0.12145996],\n",
       "       [-0.01974487],\n",
       "       [ 0.66162109],\n",
       "       [ 0.55029297],\n",
       "       [ 0.30200195],\n",
       "       [ 0.2467041 ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate predictions from the test data set\n",
    "preds = trainer.predict(test_dataset).predictions.astype(float)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "530e5247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.42993164, 0.75341797, 0.51318359, 0.24438477, 0.        ,\n",
       "       0.50439453, 0.45068359, 0.        , 0.28466797, 1.        ,\n",
       "       0.25048828, 0.22973633, 0.83105469, 0.84277344, 0.76367188,\n",
       "       0.41601562, 0.30200195, 0.        , 0.56152344, 0.43774414,\n",
       "       0.53417969, 0.24853516, 0.16418457, 0.22900391, 0.58935547,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.65136719,\n",
       "       0.12145996, 0.        , 0.66162109, 0.55029297, 0.30200195,\n",
       "       0.2467041 ])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some of them are > or < 0, lets just clip things\n",
    "preds = np.clip(preds, 0, 1)\n",
    "preds = preds.flatten()\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "426dbddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ae380aa89344a9ebb0ec9dad7a8079c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1038"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And now generate the submission.csv\n",
    "import datasets\n",
    "\n",
    "submission = datasets.Dataset.from_dict({\"id\": test_dataset[\"id\"], \"score\": preds})\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5854b6",
   "metadata": {},
   "source": [
    "When submitted to the kaggle competition this got ~0.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9d109e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
